{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN4vBe_c5Fq_",
        "outputId": "12eceb78-8d81-4a8c-b7fc-f2d4ab3d7bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLO_Road_Damage'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 11 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11/11), 10.74 KiB | 10.74 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/moienr/YOLO_Road_Damage.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "Vn3cwxOs6T1z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the cloned repository to the Python path\n",
        "sys.path.append('/content/YOLO_Road_Damage')"
      ],
      "metadata": {
        "id": "yXwiRvaD6JW0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import RDD_CLASSES\n",
        "print(RDD_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPSFMS2j6QjE",
        "outputId": "ac5ffb53-5943-47b3-e2f3-3144322e94e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['D00', 'D10', 'D20', 'D40', 'Repair', 'Block crack']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_China_Drone.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phjmD2sz5RF_",
        "outputId": "994cf876-5a23-4d33-8612-116070e714ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 14:12:22--  https://bigdatacup.s3.ap-northeast-1.amazonaws.com/2022/CRDDC2022/RDD2022/Country_Specific_Data_CRDDC2022/RDD2022_China_Drone.zip\n",
            "Resolving bigdatacup.s3.ap-northeast-1.amazonaws.com (bigdatacup.s3.ap-northeast-1.amazonaws.com)... 52.219.1.123, 52.219.8.162, 52.219.152.150, ...\n",
            "Connecting to bigdatacup.s3.ap-northeast-1.amazonaws.com (bigdatacup.s3.ap-northeast-1.amazonaws.com)|52.219.1.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 160193541 (153M) [application/zip]\n",
            "Saving to: ‘RDD2022_China_Drone.zip’\n",
            "\n",
            "RDD2022_China_Drone 100%[===================>] 152.77M  29.1MB/s    in 5.1s    \n",
            "\n",
            "2023-12-09 14:12:27 (29.9 MB/s) - ‘RDD2022_China_Drone.zip’ saved [160193541/160193541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/RDD2022_China_Drone.zip"
      ],
      "metadata": {
        "id": "rzctn5rL5foV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as FT\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from model import Yolov1\n",
        "from dataset import VOCDataset\n",
        "from utils import (\n",
        "    non_max_suppression,\n",
        "    mean_average_precision,\n",
        "    intersection_over_union,\n",
        "    cellboxes_to_boxes,\n",
        "    get_bboxes,\n",
        "    plot_image,\n",
        "    save_checkpoint,\n",
        "    load_checkpoint,\n",
        ")\n",
        "from loss import YoloLoss\n",
        "\n",
        "seed = 123\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtsxsbJq6seT",
        "outputId": "51ba7935-041a-4e63-8b3b-e20f225dd69c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7985ac8d9bf0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters etc.\n",
        "LEARNING_RATE = 2e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "BATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\n",
        "WEIGHT_DECAY = 0\n",
        "EPOCHS = 100\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "LOAD_MODEL_FILE = \"overfit.pth.tar\"\n",
        "IMG_DIR = \"/content/China_Drone/train/images\"\n",
        "LABEL_DIR = \"/content/China_Drone/train/annotations/xmls\"\n"
      ],
      "metadata": {
        "id": "rVYCacpn6tqr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, bboxes):\n",
        "        for t in self.transforms:\n",
        "            img, bboxes = t(img), bboxes\n",
        "\n",
        "        return img, bboxes\n",
        "\n",
        "\n",
        "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])\n",
        "\n",
        "\n",
        "def train_fn(train_loader, model, optimizer, loss_fn):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    mean_loss = []\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(loop):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "        mean_loss.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update progress bar\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Mean loss was {sum(mean_loss)/len(mean_loss)}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    model = Yolov1(split_size=7, num_boxes=2, num_classes=6).to(DEVICE)\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "    loss_fn = YoloLoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n",
        "\n",
        "    train_dataset = VOCDataset(\n",
        "        transform=transform,\n",
        "        img_dir=IMG_DIR,\n",
        "        label_dir=LABEL_DIR,\n",
        "    )\n",
        "\n",
        "    test_dataset = VOCDataset( transform=transform, img_dir=IMG_DIR, label_dir=LABEL_DIR,)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        # for x, y in train_loader:\n",
        "        #    x = x.to(DEVICE)\n",
        "        #    for idx in range(8):\n",
        "        #        bboxes = cellboxes_to_boxes(model(x))\n",
        "        #        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        #        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n",
        "\n",
        "        #    import sys\n",
        "        #    sys.exit()\n",
        "\n",
        "        pred_boxes, target_boxes = get_bboxes(\n",
        "            train_loader, model, iou_threshold=0.5, threshold=0.4\n",
        "        )\n",
        "\n",
        "        mean_avg_prec = mean_average_precision(\n",
        "            pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n",
        "        )\n",
        "        print(f\"Train mAP: {mean_avg_prec}\")\n",
        "\n",
        "        # if mean_avg_prec > 0.9:\n",
        "        if epoch == EPOCHS - 1:\n",
        "           checkpoint = {\n",
        "               \"state_dict\": model.state_dict(),\n",
        "               \"optimizer\": optimizer.state_dict(),\n",
        "           }\n",
        "           save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n",
        "           import time\n",
        "           time.sleep(10)\n",
        "\n",
        "        train_fn(train_loader, model, optimizer, loss_fn)\n"
      ],
      "metadata": {
        "id": "UMPDDroS5oxn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Yolov1(split_size=7, num_boxes=2, num_classes=6).to(DEVICE)\n",
        "optimizer = optim.Adam(\n",
        "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "loss_fn = YoloLoss()"
      ],
      "metadata": {
        "id": "vjtL_1kvifID"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(torch.load(\"/content/overfit.pth.tar\"), model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hNQH9896x9j",
        "outputId": "96f8cf06-a53f-4e2c-ec53-91945045412d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "-dnzf_LbjDVC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOCDataset(\n",
        "    transform=transform,\n",
        "    img_dir=IMG_DIR,\n",
        "    label_dir=LABEL_DIR,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XPjbNmz6jLfa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pred_boxes, all_true_boxes = utils.get_bboxes(train_loader,model,iou_threshold=0.5, threshold=0.4)"
      ],
      "metadata": {
        "id": "0xN4tytv7Hbt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_pred_boxes), len(all_true_boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-enfgWai-nl",
        "outputId": "46c66aa3-f39e-4706-d4b8-52fb955e4ef9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24139, 3811)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = 2\n",
        "all_pred_boxes[ix],all_true_boxes[ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2VcVET_jYSz",
        "outputId": "c35d4da3-a96c-40e6-e068-a199a2cfd1cd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1,\n",
              "  0.0,\n",
              "  0.558247983455658,\n",
              "  0.5696244835853577,\n",
              "  0.14660102128982544,\n",
              "  0.012811226770281792,\n",
              "  -0.00439764279872179],\n",
              " [2,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  0.4111328423023224,\n",
              "  0.3662109673023224,\n",
              "  0.7324219346046448,\n",
              "  0.4316406548023224])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J0gzRvWnnjT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}